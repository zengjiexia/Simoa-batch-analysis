{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5753c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4027179",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\zjxia\\iCloudDrive\\Career\\FBL_analysis\\sample_data\\FBL199 Claire Lancaster 4plexE OS 30.5.24.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b4b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6200ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = df.Unit.unique()\n",
    "df = df[['Sample Barcode', 'Assay', 'Plex', 'Location', 'Carrier Barcode',\n",
    "       'Replicate AEB', 'Mean AEB', 'SD AEB', 'CV AEB', \n",
    "        'Replicate Conc.','Mean Conc.', 'SD Conc.', 'CV Conc.',\n",
    "         #'Unit', 'Job Status', 'Job ID',\n",
    "       'Flags', 'Errors']]\n",
    "# Only keep columns listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201e444a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pg/mL'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29b0a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 calibration levels, 72 controls and 216 samples were found. \n",
      "0 entries were uncategorised.\n"
     ]
    }
   ],
   "source": [
    "# This part is more fragile than others because we are using specific condition to select data entries.\n",
    "# There should be no uncategorised entry, if there is, check the \"Sample Barcode\" naming.\n",
    "\n",
    "# Any entry with \"Calibrator\" in their \"Sample Barcode\" is a calibrator\n",
    "df_cals = df.loc[df['Sample Barcode'].str.contains('Calibrator')] \n",
    "# Any entry with \"Control\" or \"Int Ctrl\" in their \"Sample Barcode\" is a control\n",
    "df_ctrls = df.loc[(df['Sample Barcode'].str.contains('Control'))|(df['Sample Barcode'].str.contains('Int Ctrl'))]\n",
    "# All entries with numerical \"Sample Barcode\" is a sample\n",
    "df_samples = df.loc[df['Sample Barcode'].str.isnumeric()]\n",
    "\n",
    "leftover = len(df)-len(df_cals)-len(df_ctrls)-len(df_samples)\n",
    "print(f\"{len(df_cals)} calibration levels, {len(df_ctrls)} controls and {len(df_samples)} samples were found. \\n{leftover} entries were uncategorised.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3c8788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def due_with_replicates(df):\n",
    "    \"\"\"\n",
    "    input\n",
    "    \"\"\"\n",
    "    # Group by Categories and aggregate the values into lists\n",
    "    grouped_df = df.groupby(['Sample Barcode', 'Assay', 'Plex', 'Location', 'Carrier Barcode']).agg(list).reset_index()\n",
    "\n",
    "    # lambda x: [value for value in x if not pd.isna(value)] # This function returns all the non-NaN values\n",
    "    grouped_df['Replicate AEB'] = grouped_df['Replicate AEB'].apply(lambda x: [value for value in x if not pd.isna(value)])\n",
    "    grouped_df['Replicate Conc.'] = grouped_df['Replicate Conc.'].apply(lambda x: [value for value in x if not pd.isna(value)])\n",
    "\n",
    "    # Define a function to extract the first non-NaN value from a list\n",
    "    def first_non_nan(lst):\n",
    "        for item in lst:\n",
    "            if not pd.isna(item):\n",
    "                return item\n",
    "        return np.nan  # Return NaN if all values are NaN\n",
    "\n",
    "    # Manually expand the lists into separate columns\n",
    "    expanded_df = pd.DataFrame()\n",
    "    expanded_df['Sample Barcode'] = grouped_df['Sample Barcode']\n",
    "    expanded_df['Assay'] = grouped_df['Assay']\n",
    "    expanded_df['Plex'] = grouped_df['Plex']\n",
    "    expanded_df['Location'] = grouped_df['Location']\n",
    "    expanded_df['Carrier Barcode'] = grouped_df['Carrier Barcode']\n",
    "    \n",
    "    # Create new columns for each AEB replicates in the lists\n",
    "    if grouped_df['Replicate AEB'].apply(len).max() == 1:\n",
    "        expanded_df[f'Replicate AEB'] = grouped_df['Replicate AEB'].apply(first_non_nan)\n",
    "    else:\n",
    "        for i in range(grouped_df['Replicate AEB'].apply(len).max()):  # Get the maximum length of lists in Value1\n",
    "            expanded_df[f'Replicate AEB {i+1}'] = grouped_df['Replicate AEB'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "    expanded_df['Mean AEB'] = grouped_df['Mean AEB'].apply(first_non_nan)\n",
    "    expanded_df['SD AEB'] = grouped_df['SD AEB'].apply(first_non_nan)\n",
    "    expanded_df['CV AEB'] = grouped_df['CV AEB'].apply(first_non_nan)\n",
    "    \n",
    "    # Create new columns for each Conc. replicates in the lists\n",
    "    if grouped_df['Replicate Conc.'].apply(len).max() == 1:\n",
    "        expanded_df[f'Replicate Conc. ({unit[0]})'] = grouped_df['Replicate Conc.'].apply(first_non_nan)\n",
    "    else:\n",
    "        for i in range(grouped_df['Replicate Conc.'].apply(len).max()):  # Get the maximum length of lists in Value1\n",
    "            expanded_df[f'Replicate Conc. {i+1}'] = grouped_df['Replicate Conc.'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "    \n",
    "    expanded_df[f'Mean Conc. ({unit[0]})'] = grouped_df['Mean Conc.'].apply(first_non_nan)\n",
    "    expanded_df['SD Conc.'] = grouped_df['SD Conc.'].apply(first_non_nan)\n",
    "    expanded_df['CV Conc.'] = grouped_df['CV Conc.'].apply(first_non_nan)\n",
    "\n",
    "    expanded_df['Flags'] = grouped_df['Flags'].apply(first_non_nan)\n",
    "    expanded_df['Errors'] = grouped_df['Errors'].apply(first_non_nan)\n",
    "    \n",
    "    expanded_df = expanded_df.sort_values(by=['Assay', \"Plex\", 'Sample Barcode'])\n",
    "    expanded_df = expanded_df.reset_index(drop=True)\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e27845f-55da-47ee-8b62-c8c98f91ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process calibration standards\n",
    "df_cals = due_with_replicates(df_cals)\n",
    "# Process controls\n",
    "df_ctrls = due_with_replicates(df_ctrls)\n",
    "# Process samples\n",
    "df_samples = due_with_replicates(df_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c1632c3-f218-4289-94df-fd3f1864d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate intra-plate %CV\n",
    "# Based on Int Ctrls and drop all entries for machine calculated means\n",
    "df_intra_CV = df.loc[(df['Sample Barcode'].str.contains('Int Ctrl'))&(df['Replicate Conc.'].notna())]\n",
    "# Calculate for each plex\n",
    "df_intra_CV = df_intra_CV.groupby(['Assay', 'Plex']).agg(Average=('Replicate Conc.','mean'),\n",
    "                                                          Stdev=('Replicate Conc.','std'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e879494-dedd-47e5-bd39-6c45717833a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intra_CV = df_intra_CV.reset_index()\n",
    "df_intra_CV['%CV'] = df_intra_CV['Stdev']/df_intra_CV['Average']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37987d69-c329-4caa-a494-3c87973d14aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assay</th>\n",
       "      <th>Plex</th>\n",
       "      <th>Average</th>\n",
       "      <th>Stdev</th>\n",
       "      <th>%CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neuro 4-Plex E</td>\n",
       "      <td>Abeta 40</td>\n",
       "      <td>95.063798</td>\n",
       "      <td>6.283075</td>\n",
       "      <td>6.609325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neuro 4-Plex E</td>\n",
       "      <td>Abeta 42</td>\n",
       "      <td>5.232007</td>\n",
       "      <td>0.234773</td>\n",
       "      <td>4.487241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neuro 4-Plex E</td>\n",
       "      <td>GFAP</td>\n",
       "      <td>104.913739</td>\n",
       "      <td>11.589510</td>\n",
       "      <td>11.046704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neuro 4-Plex E</td>\n",
       "      <td>NF-light</td>\n",
       "      <td>25.283575</td>\n",
       "      <td>3.140094</td>\n",
       "      <td>12.419502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Assay      Plex     Average      Stdev        %CV\n",
       "0  Neuro 4-Plex E  Abeta 40   95.063798   6.283075   6.609325\n",
       "1  Neuro 4-Plex E  Abeta 42    5.232007   0.234773   4.487241\n",
       "2  Neuro 4-Plex E      GFAP  104.913739  11.589510  11.046704\n",
       "3  Neuro 4-Plex E  NF-light   25.283575   3.140094  12.419502"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intra_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31555c5-66d5-4424-9919-df7f28c7751e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25520\\3509847838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a Pandas Excel writer using XlsxWriter as the engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' sorted_1.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xlsxwriter'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Write each DataFrame to a different worksheet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Samples'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf_ctrls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Controls'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m     ):\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# Use the xlsxwriter module as the Excel writer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mxlsxwriter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWorkbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(path.replace('.csv', ' sorted_1.xlsx'), engine='xlsxwriter') as writer:\n",
    "    # Write each DataFrame to a different worksheet\n",
    "    df_samples.to_excel(writer, sheet_name='Samples', index=False)\n",
    "    df_ctrls.to_excel(writer, sheet_name='Controls', index=False)\n",
    "    df_cals.to_excel(writer, sheet_name='Cals', index=False)\n",
    "    \n",
    "    # Access the workbook and worksheet objects\n",
    "    workbook  = writer.book\n",
    "    worksheet_cal = writer.sheets['Cals']\n",
    "\n",
    "\n",
    "    # Define a format for the highlighted cells\n",
    "    highlight_format = workbook.add_format({'bg_color': 'yellow'})\n",
    "\n",
    "    # Apply conditional formatting based on criteria\n",
    "    worksheet1.conditional_format('J2:J1000', {'type': 'cell',\n",
    "                                            'criteria': '>',\n",
    "                                            'value': 0.15,\n",
    "                                            'format': highlight_format})\n",
    "\n",
    "print(\"Excel file with highlighted cells created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713eeae-9617-49f3-bc51-8f420101fe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189ff02-6ed4-45f8-9944-88378e520156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3ml",
   "language": "python",
   "name": "py3ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
